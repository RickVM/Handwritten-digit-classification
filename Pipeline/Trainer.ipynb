{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting model training..\n",
      "--------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "classicML = False #Used in saving process \n",
    "\n",
    "print(\"\\n\\nStarting model training..\")\n",
    "print(\"--------------------------------------\\n\")\n",
    "train_df = pd.read_csv(\"data.csv\")\n",
    "X = train_df.iloc[:,1:]\n",
    "y = train_df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "if classicML:\n",
    "    # XGBoost Code\n",
    "    import xgboost as xgb\n",
    "    from xgboost import XGBClassifier\n",
    "    #Default settings - Now deprecated with optimized settings. \n",
    "    #pipeline = Pipeline(steps=[('minmaxscaler', MinMaxScaler(feature_range=(0, 1), copy=True)),\n",
    "    #                            ('XgbClassifier', XGBClassifier(objective = 'multi:softmax'))\n",
    "    #                           ])\n",
    "    #Based upon random search results.\n",
    "    #Accuracy score was 91% on 20% of the training data.\n",
    "    pipeline = Pipeline(steps=[('minmaxscaler', MinMaxScaler(feature_range=(0, 1), copy=True)),\n",
    "                               ('XgbClassifier', XGBClassifier(objective = 'multi:softmax',\n",
    "                                                               gamma = 0.9,\n",
    "                                                               learning_rate = 0.375,\n",
    "                                                               max_depth = 9,\n",
    "                                                               n_estimators = 9))])\n",
    "\n",
    "else:\n",
    "    pipeline = Pipeline(steps=[('minmaxscaler', MinMaxScaler(feature_range=(0, 1), copy=True))  ])\n",
    "\n",
    "    from keras.models import Model\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Input, Dense\n",
    "    from keras.losses import sparse_categorical_crossentropy\n",
    "    from keras.optimizers import SGD\n",
    "    def create_model():\n",
    "        model = Sequential()\n",
    "        #units = (Input+Output)/2\n",
    "        model.add(Dense(units = (int(round(len(X.columns)+9)/2)), activation = 'relu', input_dim= len(X.columns))) \n",
    "        model.add(Dense(10, activation = 'softmax'))\n",
    "        model.compile(loss=sparse_categorical_crossentropy,\n",
    "                      optimizer='adam', metrics = ['accuracy'])\n",
    "        #SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "        return model\n",
    "    classifier = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By creating a pipeline we can run one line of code to pre-process our data and train our model.\n",
    "Later on this pipeline will also enable us to only need 1 line of code to pre-process and make predictions on new data.\n",
    "Hence the code will be a lot cleaner.\n",
    "\n",
    "Pipeline.steps can be called to view the all the components and parameters that make up the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random search code\n",
    "\n",
    "# X = train_df.iloc[:,1:]\n",
    "# y = train_df.iloc[:,0]\n",
    "\n",
    "# from scipy.stats import randint\n",
    "# import scipy\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# import xgboost as xgb\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0,1), copy=True)\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# params = {'max_depth': randint(1, 10) ,\n",
    "#           'learning_rate': scipy.stats.expon(scale=0.5),\n",
    "#           'n_estimators': randint(1, 10),\n",
    "#           'gamma': scipy.stats.expon(scale=1)\n",
    "#            }\n",
    "\n",
    "\n",
    "# import datetime\n",
    "# print(\"\\n\\nStarting parameter search..\")\n",
    "# print(\"--------------------------------------\\n\")\n",
    "# tstart = datetime.datetime.now()\n",
    "# optimizer = RandomizedSearchCV(XGBClassifier(objective = 'multi:softmax'), params, n_iter = 25)\n",
    "# optimizer.fit(X, y)\n",
    "# tstop = datetime.datetime.now()\n",
    "# tdelta = tstop - tstart\n",
    "# print(\"Finished training.\")\n",
    "# print(\"Training duration in (Days/Hours/Seconds/Milliseconds): {0}\".format(tdelta)) \n",
    "# print(optimizer.score()) #0.91130952380952379\n",
    "# print(optimizer.best_params_) #{'gamma': 0.90390078036156596,\n",
    "#                               #'learning_rate': 0.37483528867120858,\n",
    "#                               #'max_depth': 9,\n",
    "#                               #'n_estimators': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7560 samples, validate on 840 samples\n",
      "Epoch 1/50\n",
      "7560/7560 [==============================] - 1s 82us/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.2159 - val_acc: 0.9571\n",
      "Epoch 2/50\n",
      "7560/7560 [==============================] - 1s 73us/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.2140 - val_acc: 0.9560\n",
      "Epoch 3/50\n",
      "7560/7560 [==============================] - 1s 82us/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.2144 - val_acc: 0.9571\n",
      "Epoch 4/50\n",
      "7560/7560 [==============================] - 1s 74us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.2142 - val_acc: 0.9571\n",
      "Epoch 5/50\n",
      "7560/7560 [==============================] - 1s 83us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.2152 - val_acc: 0.9560\n",
      "Epoch 6/50\n",
      "7560/7560 [==============================] - 1s 73us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.2166 - val_acc: 0.9560\n",
      "Epoch 7/50\n",
      "7560/7560 [==============================] - 1s 78us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.2144 - val_acc: 0.9560\n",
      "Epoch 8/50\n",
      "7560/7560 [==============================] - 1s 73us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.2172 - val_acc: 0.9583\n",
      "Epoch 9/50\n",
      "7560/7560 [==============================] - 1s 81us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.2151 - val_acc: 0.9571\n",
      "Epoch 10/50\n",
      "7560/7560 [==============================] - 1s 73us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.2170 - val_acc: 0.9571\n",
      "Epoch 11/50\n",
      "7560/7560 [==============================] - 1s 72us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.2171 - val_acc: 0.9560\n",
      "Epoch 12/50\n",
      "7560/7560 [==============================] - 1s 73us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.2170 - val_acc: 0.9571\n",
      "Epoch 13/50\n",
      "7560/7560 [==============================] - 1s 76us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.2176 - val_acc: 0.9560\n",
      "Epoch 14/50\n",
      "7560/7560 [==============================] - 1s 75us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.2173 - val_acc: 0.9583\n",
      "Epoch 15/50\n",
      "7560/7560 [==============================] - 1s 70us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.2182 - val_acc: 0.9548\n",
      "Epoch 16/50\n",
      "7560/7560 [==============================] - 1s 73us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.2180 - val_acc: 0.9571\n",
      "Epoch 17/50\n",
      "7560/7560 [==============================] - 1s 73us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.2199 - val_acc: 0.9583\n",
      "Epoch 18/50\n",
      "7560/7560 [==============================] - 1s 82us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.2179 - val_acc: 0.9571\n",
      "Epoch 19/50\n",
      "7560/7560 [==============================] - 1s 67us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.2196 - val_acc: 0.9571\n",
      "Epoch 20/50\n",
      "7560/7560 [==============================] - 1s 71us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.2199 - val_acc: 0.9571\n",
      "Epoch 21/50\n",
      "7560/7560 [==============================] - 1s 78us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.2200 - val_acc: 0.9583\n",
      "Epoch 22/50\n",
      "7560/7560 [==============================] - 1s 78us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.2195 - val_acc: 0.9571\n",
      "Epoch 23/50\n",
      "7560/7560 [==============================] - 1s 88us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2208 - val_acc: 0.9583\n",
      "Epoch 24/50\n",
      "7560/7560 [==============================] - 1s 77us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2205 - val_acc: 0.9571\n",
      "Epoch 25/50\n",
      "7560/7560 [==============================] - 1s 73us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2212 - val_acc: 0.9571\n",
      "Epoch 26/50\n",
      "7560/7560 [==============================] - 1s 71us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2213 - val_acc: 0.9583\n",
      "Epoch 27/50\n",
      "7560/7560 [==============================] - 1s 76us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2222 - val_acc: 0.9583\n",
      "Epoch 28/50\n",
      "7560/7560 [==============================] - 1s 74us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2210 - val_acc: 0.9583\n",
      "Epoch 29/50\n",
      "7560/7560 [==============================] - 1s 73us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2227 - val_acc: 0.9571\n",
      "Epoch 30/50\n",
      "7560/7560 [==============================] - 1s 73us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2240 - val_acc: 0.9583\n",
      "Epoch 31/50\n",
      "7560/7560 [==============================] - 1s 71us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2223 - val_acc: 0.9571\n",
      "Epoch 32/50\n",
      "7560/7560 [==============================] - 1s 74us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2240 - val_acc: 0.9571\n",
      "Epoch 33/50\n",
      "7560/7560 [==============================] - 1s 74us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2231 - val_acc: 0.9571\n",
      "Epoch 34/50\n",
      "7560/7560 [==============================] - 1s 72us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2239 - val_acc: 0.9571\n",
      "Epoch 35/50\n",
      "7560/7560 [==============================] - 1s 73us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2260 - val_acc: 0.9583\n",
      "Epoch 36/50\n",
      "7560/7560 [==============================] - 1s 75us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2253 - val_acc: 0.9583\n",
      "Epoch 37/50\n",
      "7560/7560 [==============================] - 1s 80us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2275 - val_acc: 0.9583\n",
      "Epoch 38/50\n",
      "7560/7560 [==============================] - 1s 71us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.2253 - val_acc: 0.9583\n",
      "Epoch 39/50\n",
      "7560/7560 [==============================] - 1s 72us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.2260 - val_acc: 0.9560\n",
      "Epoch 40/50\n",
      "7560/7560 [==============================] - 1s 72us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.2262 - val_acc: 0.9583\n",
      "Epoch 41/50\n",
      "7560/7560 [==============================] - 1s 72us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.2236 - val_acc: 0.9583\n",
      "Epoch 42/50\n",
      "7560/7560 [==============================] - 1s 75us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.2296 - val_acc: 0.9571\n",
      "Epoch 43/50\n",
      "7560/7560 [==============================] - 1s 71us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.2272 - val_acc: 0.9583\n",
      "Epoch 44/50\n",
      "7560/7560 [==============================] - 1s 73us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.2284 - val_acc: 0.9595\n",
      "Epoch 45/50\n",
      "7560/7560 [==============================] - 1s 75us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.2283 - val_acc: 0.9595\n",
      "Epoch 46/50\n",
      "7560/7560 [==============================] - 1s 74us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.2288 - val_acc: 0.9583\n",
      "Epoch 47/50\n",
      "7560/7560 [==============================] - 1s 80us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.2281 - val_acc: 0.9571\n",
      "Epoch 48/50\n",
      "7560/7560 [==============================] - 1s 71us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.2285 - val_acc: 0.9583\n",
      "Epoch 49/50\n",
      "7560/7560 [==============================] - 1s 75us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.2283 - val_acc: 0.9595\n",
      "Epoch 50/50\n",
      "7560/7560 [==============================] - 1s 79us/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.2290 - val_acc: 0.9595\n",
      "Finished training.\n",
      "Training duration in (/Hours/Minutes/Seconds/Milliseconds): 0:00:28.552323\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "tstart = datetime.datetime.now()\n",
    "if classicML:\n",
    "    pipeline.fit(X, y)\n",
    "else:\n",
    "    X = pipeline.fit_transform(X, y)\n",
    "    history = classifier.fit(X, y, batch_size = 128, epochs = 50, verbose = 1, validation_split=0.1)\n",
    "\n",
    "tstop = datetime.datetime.now()\n",
    "tdelta = tstop - tstart\n",
    "print(\"Finished training.\")\n",
    "print(\"Training duration in (/Hours/Minutes/Seconds/Milliseconds): {0}\".format(tdelta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f82d9b54198>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEGirAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f829b734940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#If you want to visualize the xgboost decision tree..\n",
    "#clf = pipeline.steps[1]\n",
    "#graph = xgb.to_graphviz(clf[1])\n",
    "#graph.render('pipelinetree')\n",
    "\n",
    "#If you want to visualize the deep learning classifier\n",
    "history.history.keys()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "history.history.keys()\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title(\"Training accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acccuracy\")\n",
    "plt.legend(['Validation accuracy', 'Train accuracy'])\n",
    "#seaborn.lmplot(x = history.history['Epoch'], y = history.history['val_acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dont evaluate the model as this is up to the watcher, thus we save it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline has been saved as pipeline.pkl\n",
      "Model has been saved as model.h5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "if classicML:\n",
    "    joblib.dump(pipeline, \"pipeline.pkl\")\n",
    "    print(\"Pipeline has been saved as pipeline.pkl\")\n",
    "else:\n",
    "    joblib.dump(pipeline, \"pipeline.pkl\")\n",
    "    joblib.dump(history.history, \"history.pkl\")\n",
    "    print(\"Pipeline has been saved as pipeline.pkl\")\n",
    "    classifier.save('model.h5')\n",
    "    print(\"Model has been saved as model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
